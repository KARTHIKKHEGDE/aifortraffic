# Multi-Agent Reinforcement Learning for Adaptive Traffic Signal Control

## Bangalore Real Intersections with Emergency Vehicle Priority and Weather-Aware Optimization

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![SUMO 1.15+](https://img.shields.io/badge/SUMO-1.15+-green.svg)](https://sumo.dlr.de/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ Project Overview

This project implements a **production-grade Multi-Agent Reinforcement Learning (MARL)** system for adaptive traffic signal control operating on **real Bangalore city intersections**. The system uses actual OpenStreetMap data and SUMO microscopic traffic simulation.

### Target Intersections

1. **Silk Board Junction** (Primary - Most congested intersection in India)
2. **Tin Factory Junction**
3. **Hebbal Flyover Junction**
4. **Marathahalli - Outer Ring Road Junction**

### Key Features

- âœ… Real Bangalore road network from OpenStreetMap
- âœ… Multi-Agent RL controlling 4 interconnected junctions
- âœ… Emergency vehicle (ambulance) priority with green corridor
- âœ… Weather-aware signal timing (rain adaptation)
- âœ… Configurable queue length system (baseline â†’ realistic â†’ calibrated)
- âœ… Comprehensive evaluation against fixed-time and actuated baselines

## ğŸ“Š Performance Targets

| Metric                       | Fixed-Time  | RL Target    | Improvement |
| ---------------------------- | ----------- | ------------ | ----------- |
| Avg Waiting Time             | 180s        | <120s        | 33%+        |
| Queue Length                 | 45 vehicles | <30 vehicles | 33%+        |
| Emergency Clearance          | 90s         | <30s         | 67%+        |
| Rain Performance Degradation | 40%         | <15%         | 62%+        |

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BANGALORE RL TRAFFIC CONTROL                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Silk Board  â”‚  â”‚ Tin Factory â”‚  â”‚   Hebbal    â”‚  ...        â”‚
â”‚  â”‚   Agent     â”‚  â”‚   Agent     â”‚  â”‚   Agent     â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                â”‚                â”‚                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                          â–¼                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚              â”‚   PPO Policy Network â”‚                           â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                          â”‚                                      â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚         â–¼                â–¼                â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Emergency  â”‚  â”‚   Weather   â”‚  â”‚   Queue     â”‚             â”‚
â”‚  â”‚  Priority   â”‚  â”‚   Model     â”‚  â”‚   Config    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚              â”‚   SUMO Simulator     â”‚                           â”‚
â”‚              â”‚   (TraCI Interface)  â”‚                           â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- SUMO 1.15+ (with TraCI)
- CUDA-capable GPU (recommended for training)

### Installation

```bash
# 1. Clone/navigate to project
cd aifortraffic

# 2. Create virtual environment
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# 3. Install dependencies
pip install -r requirements.txt

# 4. Install SUMO (if not installed)
# Windows: Download from https://sumo.dlr.de/docs/Downloads.php
# Set SUMO_HOME environment variable

# 5. Acquire and prepare maps
python scripts/01_download_osm.py
python scripts/02_convert_to_sumo.py

# 6. Generate traffic demand
python scripts/03_generate_routes.py

# 7. Train RL agents
python scripts/04_train_curriculum.py --agent dqn

# 8. Evaluate
python scripts/05_evaluate.py --agent-type dqn --model-path runs/<experiment>/final_model_dqn.pt --report

# 9. Visualize results
python scripts/06_visualize.py --results runs/<experiment>/training_results.json

# 10. Run demo
python scripts/07_demo.py --agent-type dqn --model-path runs/<experiment>/final_model_dqn.pt
```

## ğŸ“ Project Structure

```
aifortraffic/
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ configs/                    # Configuration files
â”‚   â”œâ”€â”€ env_config.yaml         # Environment settings
â”‚   â”œâ”€â”€ training_config.yaml    # Training hyperparameters
â”‚   â””â”€â”€ junctions.yaml          # Bangalore junction coordinates
â”œâ”€â”€ data/                       # Raw data
â”‚   â””â”€â”€ osm/                    # OpenStreetMap files
â”œâ”€â”€ maps/                       # SUMO network files
â”œâ”€â”€ routes/                     # Traffic demand files
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ environment/            # RL environment
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ traffic_env.py      # Gymnasium environment
â”‚   â”‚   â”œâ”€â”€ sumo_connector.py   # TraCI interface
â”‚   â”‚   â””â”€â”€ queue_config.py     # Queue length modes
â”‚   â”œâ”€â”€ agents/                 # RL algorithms
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ qlearning.py        # Tabular Q-Learning
â”‚   â”‚   â”œâ”€â”€ dqn_agent.py        # Deep Q-Network
â”‚   â”‚   â””â”€â”€ ppo_agent.py        # PPO Multi-Agent
â”‚   â”œâ”€â”€ emergency/              # Emergency priority
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ priority_handler.py # Ambulance detection & override
â”‚   â”œâ”€â”€ weather/                # Weather modeling
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ weather_model.py    # Bangalore rain patterns
â”‚   â”œâ”€â”€ evaluation/             # Metrics & evaluation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py          # Traffic metrics
â”‚   â”‚   â”œâ”€â”€ baselines.py        # Fixed-time & actuated
â”‚   â”‚   â””â”€â”€ analyzer.py         # Results analysis
â”‚   â””â”€â”€ utils/                  # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # Configuration management
â”‚       â”œâ”€â”€ logger.py           # Logging utilities
â”‚       â””â”€â”€ sumo_utils.py       # SUMO helpers
â”œâ”€â”€ scripts/                    # Executable scripts
â”‚   â”œâ”€â”€ 01_download_osm.py      # Download OSM data
â”‚   â”œâ”€â”€ 02_convert_to_sumo.py   # Convert to SUMO network
â”‚   â”œâ”€â”€ 03_generate_routes.py   # Generate traffic routes
â”‚   â”œâ”€â”€ 04_train_curriculum.py  # Curriculum learning
â”‚   â”œâ”€â”€ 05_evaluate.py          # Evaluate agents
â”‚   â”œâ”€â”€ 06_visualize.py         # Generate plots
â”‚   â””â”€â”€ 07_demo.py              # Interactive demo
â”œâ”€â”€ runs/                       # Training experiments
â””â”€â”€ tests/                      # Unit tests
```

## ğŸ® Usage

### Training

```bash
# Train with Q-Learning (fast, for testing)
python scripts/04_train_curriculum.py --agent qlearning

# Train with DQN (recommended)
python scripts/04_train_curriculum.py --agent dqn --device cuda

# Train with PPO Multi-Agent (best performance)
python scripts/04_train_curriculum.py --agent ppo --device cuda

# Train specific curriculum stage
python scripts/04_train_curriculum.py --agent dqn --stage 2

# Resume from checkpoint
python scripts/04_train_curriculum.py --agent dqn --checkpoint runs/.../checkpoint.pt
```

### Evaluation

```bash
# Evaluate trained agent vs baselines
python scripts/05_evaluate.py \
    --agent-type dqn \
    --model-path runs/<experiment>/final_model_dqn.pt \
    --episodes 20 \
    --report

# Evaluate specific junction
python scripts/05_evaluate.py \
    --agent-type dqn \
    --model-path runs/<experiment>/final_model_dqn.pt \
    --junction silk_board
```

### Visualization

```bash
# Generate all plots
python scripts/06_visualize.py --results evaluation_results.json --plot-type all

# Generate specific plot types
python scripts/06_visualize.py --results evaluation_results.json --plot-type training
python scripts/06_visualize.py --results evaluation_results.json --plot-type comparison
python scripts/06_visualize.py --results evaluation_results.json --plot-type radar
```

### Demo

```bash
# Run interactive demo with SUMO-GUI
python scripts/07_demo.py \
    --agent-type dqn \
    --model-path runs/<experiment>/final_model_dqn.pt \
    --junction silk_board \
    --render

# Compare baselines only
python scripts/07_demo.py --baseline-only --junction silk_board
```

## âš™ï¸ Configuration

### Environment Config (`configs/env_config.yaml`)

```yaml
# Key settings
simulation:
  step_length: 1.0
  max_steps: 3600
  gui: false

state:
  queue_mode: "realistic_bangalore" # baseline, realistic_bangalore, calibrated

reward:
  waiting_time_weight: -0.4
  queue_length_weight: -0.3
  emergency_weight: -0.5
  throughput_weight: 0.2

emergency:
  enabled: true
  priority_time: 30
  detection_range: 200

weather:
  enabled: true
  rain_probability: 0.15
```

### Training Config (`configs/training_config.yaml`)

```yaml
# Curriculum stages
curriculum:
  stages:
    - name: basic
      episodes: 100
      weather_enabled: false
      emergency_enabled: false
    - name: weather
      episodes: 150
      weather_enabled: true
    - name: emergency
      episodes: 200
      emergency_enabled: true
    - name: full
      episodes: 300
      weather_enabled: true
      emergency_enabled: true
      multi_junction: true

# Agent hyperparameters
dqn:
  learning_rate: 0.001
  gamma: 0.95
  epsilon_decay: 0.995
  buffer_size: 100000
  batch_size: 64
  target_update_freq: 500
  hidden_layers: [256, 256, 128]
  double: true
  dueling: false

ppo:
  learning_rate: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  clip_range: 0.2
```

## ğŸ“Š Queue Length Modes

The system supports three queue length simulation modes:

| Mode                  | Description                        | Queue Multiplier |
| --------------------- | ---------------------------------- | ---------------- |
| `baseline`            | Standard SUMO values               | 1.0x             |
| `realistic_bangalore` | Bangalore congestion patterns      | 1.5-2.8x         |
| `calibrated`          | Sensor-calibrated (when available) | Custom           |

Junction-specific multipliers:

- **Silk Board**: 2.8x (India's most congested)
- **Marathahalli**: 2.2x
- **Tin Factory**: 2.0x
- **Hebbal**: 1.8x

## ğŸ“– Documentation

- [Architecture Design](docs/architecture.md)
- [Training Guide](docs/training_guide.md)
- [Evaluation Protocol](docs/evaluation_protocol.md)
- [API Reference](docs/api_reference.md)

## ğŸ”¬ Research Contributions

1. **First RL system on actual Bangalore congestion hotspots**
2. **Configurable queue length simulation** (baseline â†’ realistic â†’ calibrated)
3. **Emergency priority integrated into MARL framework**
4. **Weather-aware reward function with safety constraints**
5. **Transferable methodology for Indian cities**

## ğŸ“ Citation

```bibtex
@article{bangalore_rl_traffic_2024,
  title={Multi-Agent Reinforcement Learning for Emergency-Aware Traffic Signal Control on Real Urban Networks: A Bangalore Case Study},
  author={Your Name},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2024}
}
```

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details.
#   a i f o r t r a f f i c  
 